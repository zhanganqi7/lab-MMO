{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d794a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Hиколaй Эрнeстович Бaумaн родился в семье владельца обойной и столярной мастерской. В 1891—1895 годах был студентом Казанского ветеринарного института. В годы учёбы увлёкся нелегальной народнической и марксистской литературой, участвовал в работе подпольных рабочих кружков.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b9d2f",
   "metadata": {},
   "source": [
    "# Задание1:Для произвольного предложения или текста решите следующие задачи:\n",
    "Токенизация.\n",
    "Частеречная разметка.\n",
    "Лемматизация.\n",
    "Выделение (распознавание) именованных сущностей.\n",
    "Разбор предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8c751",
   "metadata": {},
   "source": [
    "# 1. Токенизация\n",
    "Для выполнения работы испоьзована библиотека 'Natasha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96651ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 1, 'H'),\n",
       " Substring(1, 5, 'икол'),\n",
       " Substring(5, 6, 'a'),\n",
       " Substring(6, 7, 'й'),\n",
       " Substring(8, 11, 'Эрн'),\n",
       " Substring(11, 12, 'e'),\n",
       " Substring(12, 18, 'стович'),\n",
       " Substring(19, 20, 'Б'),\n",
       " Substring(20, 21, 'a'),\n",
       " Substring(21, 23, 'ум'),\n",
       " Substring(23, 24, 'a'),\n",
       " Substring(24, 25, 'н'),\n",
       " Substring(26, 33, 'родился'),\n",
       " Substring(34, 35, 'в'),\n",
       " Substring(36, 41, 'семье'),\n",
       " Substring(42, 51, 'владельца'),\n",
       " Substring(52, 59, 'обойной'),\n",
       " Substring(60, 61, 'и'),\n",
       " Substring(62, 71, 'столярной'),\n",
       " Substring(72, 82, 'мастерской'),\n",
       " Substring(82, 83, '.'),\n",
       " Substring(84, 85, 'В'),\n",
       " Substring(86, 95, '1891—1895'),\n",
       " Substring(96, 101, 'годах'),\n",
       " Substring(102, 105, 'был'),\n",
       " Substring(106, 115, 'студентом'),\n",
       " Substring(116, 126, 'Казанского'),\n",
       " Substring(127, 140, 'ветеринарного'),\n",
       " Substring(141, 150, 'института'),\n",
       " Substring(150, 151, '.'),\n",
       " Substring(152, 153, 'В'),\n",
       " Substring(154, 158, 'годы'),\n",
       " Substring(159, 164, 'учёбы'),\n",
       " Substring(165, 172, 'увлёкся'),\n",
       " Substring(173, 184, 'нелегальной'),\n",
       " Substring(185, 198, 'народнической'),\n",
       " Substring(199, 200, 'и'),\n",
       " Substring(201, 213, 'марксистской'),\n",
       " Substring(214, 225, 'литературой'),\n",
       " Substring(225, 226, ','),\n",
       " Substring(227, 237, 'участвовал'),\n",
       " Substring(238, 239, 'в'),\n",
       " Substring(240, 246, 'работе'),\n",
       " Substring(247, 257, 'подпольных'),\n",
       " Substring(258, 265, 'рабочих'),\n",
       " Substring(266, 273, 'кружков'),\n",
       " Substring(273, 274, '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize, sentenize\n",
    "n_tok_text = list(tokenize(text))\n",
    "n_tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c10b7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'икол',\n",
       " 'a',\n",
       " 'й',\n",
       " 'Эрн',\n",
       " 'e',\n",
       " 'стович',\n",
       " 'Б',\n",
       " 'a',\n",
       " 'ум',\n",
       " 'a',\n",
       " 'н',\n",
       " 'родился',\n",
       " 'в',\n",
       " 'семье',\n",
       " 'владельца',\n",
       " 'обойной',\n",
       " 'и',\n",
       " 'столярной',\n",
       " 'мастерской',\n",
       " '.',\n",
       " 'В',\n",
       " '1891—1895',\n",
       " 'годах',\n",
       " 'был',\n",
       " 'студентом',\n",
       " 'Казанского',\n",
       " 'ветеринарного',\n",
       " 'института',\n",
       " '.',\n",
       " 'В',\n",
       " 'годы',\n",
       " 'учёбы',\n",
       " 'увлёкся',\n",
       " 'нелегальной',\n",
       " 'народнической',\n",
       " 'и',\n",
       " 'марксистской',\n",
       " 'литературой',\n",
       " ',',\n",
       " 'участвовал',\n",
       " 'в',\n",
       " 'работе',\n",
       " 'подпольных',\n",
       " 'рабочих',\n",
       " 'кружков',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_tok_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53c69ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0,\n",
       "           83,\n",
       "           'Hиколaй Эрнeстович Бaумaн родился в семье владельца обойной и столярной мастерской.'),\n",
       " Substring(84,\n",
       "           151,\n",
       "           'В 1891—1895 годах был студентом\\xa0Казанского ветеринарного института.'),\n",
       " Substring(152,\n",
       "           274,\n",
       "           'В годы учёбы увлёкся нелегальной народнической и марксистской литературой, участвовал в работе подпольных рабочих кружков.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_text = list(sentenize(text))\n",
    "n_sen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b102f090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hиколaй Эрнeстович Бaумaн родился в семье владельца обойной и столярной мастерской.',\n",
       "  'В 1891—1895 годах был студентом\\xa0Казанского ветеринарного института.',\n",
       "  'В годы учёбы увлёкся нелегальной народнической и марксистской литературой, участвовал в работе подпольных рабочих кружков.'],\n",
       " 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e9994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sentenize(text):\n",
    "    n_sen_chunk = []\n",
    "    for sent in sentenize(text):\n",
    "        tokens = [_.text for _ in tokenize(sent.text)]\n",
    "        n_sen_chunk.append(tokens)\n",
    "    return n_sen_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8030b908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['H',\n",
       "  'икол',\n",
       "  'a',\n",
       "  'й',\n",
       "  'Эрн',\n",
       "  'e',\n",
       "  'стович',\n",
       "  'Б',\n",
       "  'a',\n",
       "  'ум',\n",
       "  'a',\n",
       "  'н',\n",
       "  'родился',\n",
       "  'в',\n",
       "  'семье',\n",
       "  'владельца',\n",
       "  'обойной',\n",
       "  'и',\n",
       "  'столярной',\n",
       "  'мастерской',\n",
       "  '.'],\n",
       " ['В',\n",
       "  '1891—1895',\n",
       "  'годах',\n",
       "  'был',\n",
       "  'студентом',\n",
       "  'Казанского',\n",
       "  'ветеринарного',\n",
       "  'института',\n",
       "  '.'],\n",
       " ['В',\n",
       "  'годы',\n",
       "  'учёбы',\n",
       "  'увлёкся',\n",
       "  'нелегальной',\n",
       "  'народнической',\n",
       "  'и',\n",
       "  'марксистской',\n",
       "  'литературой',\n",
       "  ',',\n",
       "  'участвовал',\n",
       "  'в',\n",
       "  'работе',\n",
       "  'подпольных',\n",
       "  'рабочих',\n",
       "  'кружков',\n",
       "  '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk = n_sentenize(text)\n",
    "n_sen_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87c669",
   "metadata": {},
   "source": [
    "# 2.Частеречная разметка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdf92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from slovnet import Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21efe3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e2b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b26aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_res = n_morph.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a664d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pos(markup):\n",
    "    for token in markup.tokens:\n",
    "        print('{} - {}'.format(token.text, token.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173adda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H - NOUN\n",
      "икол - X|Foreign=Yes\n",
      "a - X|Foreign=Yes\n",
      "й - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "Эрн - PROPN|Foreign=Yes\n",
      "e - X|Foreign=Yes\n",
      "стович - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "Б - PROPN\n",
      "a - X|Foreign=Yes\n",
      "ум - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "a - NOUN\n",
      "н - X|Foreign=Yes\n",
      "родился - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
      "в - ADP\n",
      "семье - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
      "владельца - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
      "обойной - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
      "и - CCONJ\n",
      "столярной - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "мастерской - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      ". - PUNCT\n",
      "В - ADP\n",
      "1891—1895 - ADJ\n",
      "годах - NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Plur\n",
      "был - AUX|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "студентом - NOUN|Animacy=Anim|Case=Ins|Gender=Masc|Number=Sing\n",
      "Казанского - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "ветеринарного - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "института - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      ". - PUNCT\n",
      "В - ADP\n",
      "годы - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
      "учёбы - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "увлёкся - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
      "нелегальной - ADJ|Case=Ins|Degree=Pos|Gender=Fem|Number=Sing\n",
      "народнической - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
      "и - CCONJ\n",
      "марксистской - ADJ|Case=Ins|Degree=Pos|Gender=Fem|Number=Sing\n",
      "литературой - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
      ", - PUNCT\n",
      "участвовал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "в - ADP\n",
      "работе - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
      "подпольных - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "рабочих - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "кружков - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
      ". - PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
    "[print_pos(x) for x in n_text_markup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf479fa2",
   "metadata": {},
   "source": [
    "# 3.Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1438ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b95443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_lemmatize(text):\n",
    "    emb = NewsEmbedding()\n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "    segmenter = Segmenter()\n",
    "    morph_vocab = MorphVocab()\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e37314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 'h',\n",
       " 'икол': 'икол',\n",
       " 'a': 'a',\n",
       " 'й': 'й',\n",
       " 'Эрн': 'эрна',\n",
       " 'e': 'e',\n",
       " 'стович': 'стович',\n",
       " 'Б': 'б',\n",
       " 'ум': 'ум',\n",
       " 'н': 'н',\n",
       " 'родился': 'родиться',\n",
       " 'в': 'в',\n",
       " 'семье': 'семья',\n",
       " 'владельца': 'владелец',\n",
       " 'обойной': 'обойный',\n",
       " 'и': 'и',\n",
       " 'столярной': 'столярный',\n",
       " 'мастерской': 'мастерская',\n",
       " '.': '.',\n",
       " 'В': 'в',\n",
       " '1891—1895': '1891—1895',\n",
       " 'годах': 'год',\n",
       " 'был': 'быть',\n",
       " 'студентом': 'студент',\n",
       " 'Казанского': 'казанский',\n",
       " 'ветеринарного': 'ветеринарный',\n",
       " 'института': 'институт',\n",
       " 'годы': 'год',\n",
       " 'учёбы': 'учеба',\n",
       " 'увлёкся': 'увлечься',\n",
       " 'нелегальной': 'нелегальный',\n",
       " 'народнической': 'народнический',\n",
       " 'марксистской': 'марксистский',\n",
       " 'литературой': 'литература',\n",
       " ',': ',',\n",
       " 'участвовал': 'участвовать',\n",
       " 'работе': 'работа',\n",
       " 'подпольных': 'подпольный',\n",
       " 'рабочих': 'рабочий',\n",
       " 'кружков': 'кружок'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc = n_lemmatize(text)\n",
    "{_.text: _.lemma for _ in n_doc.tokens}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c32349",
   "metadata": {},
   "source": [
    "# 4.Выделение (распознавание) именованных сущностей\n",
    "named-entity recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cef4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b40c6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = NER.load('slovnet_ner_news_v1.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4871ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_res = ner.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd5d725b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpanMarkup(\n",
       "    text='Hиколaй Эрнeстович Бaумaн родился в семье владельца обойной и столярной мастерской. В 1891—1895 годах был студентом\\xa0Казанского ветеринарного института. В годы учёбы увлёкся нелегальной народнической и марксистской литературой, участвовал в работе подпольных рабочих кружков.',\n",
       "    spans=[Span(\n",
       "         start=116,\n",
       "         stop=150,\n",
       "         type='ORG'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup_ner = ner(text)\n",
    "markup_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555861e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hиколaй Эрнeстович Бaумaн родился в семье владельца обойной и \n",
      "столярной мастерской. В 1891—1895 годах был студентом Казанского \n",
      "                                                      ORG────────\n",
      "ветеринарного института. В годы учёбы увлёкся нелегальной \n",
      "───────────────────────                                   \n",
      "народнической и марксистской литературой, участвовал в работе \n",
      "подпольных рабочих кружков.\n"
     ]
    }
   ],
   "source": [
    "show_markup(markup_ner.text, markup_ner.spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c065b",
   "metadata": {},
   "source": [
    "# 5.Разбор предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80a28971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import NewsSyntaxParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "874cec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2269ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────► H          advmod\n",
      "│ ┌►┌─┌─┌─┌─ икол       obl\n",
      "│ │ │ │ │ └► a          appos\n",
      "│ │ │ │ └►┌─ й          appos\n",
      "│ │ │ │   └► Эрн        nmod\n",
      "│ │ │ │   ┌► e          appos\n",
      "│ │ │ └►┌─└─ стович     appos\n",
      "│ │ │ ┌─└►┌─ Б          appos\n",
      "│ │ │ │   └► a          appos\n",
      "│ │ └►│   ┌─ ум         appos\n",
      "│ │   └──►│  a          flat:foreign\n",
      "│ │       └► н          appos\n",
      "└─└─┌───┌─── родился    \n",
      "    │   │ ┌► в          case\n",
      "    │   └►└─ семье      obl\n",
      "    │ ┌─└►┌─ владельца  nmod\n",
      "    │ │ ┌─└► обойной    nmod\n",
      "    │ │ │ ┌► и          cc\n",
      "    │ │ └►└─ столярной  conj\n",
      "    │ └────► мастерской nmod\n",
      "    └──────► .          punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.parse_syntax(syntax_parser)\n",
    "n_doc.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8f4bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ┌──► В             case\n",
      "      │ ┌► 1891—1895     amod\n",
      "    ┌►└─└─ годах         nmod\n",
      "    │   ┌► был           cop\n",
      "┌─┌─└───└─ студентом     \n",
      "│ │   ┌──► Казанского    amod\n",
      "│ │   │ ┌► ветеринарного amod\n",
      "│ └──►└─└─ института     nmod\n",
      "└────────► .             punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.sents[1].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d76f1f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ┌► В             case\n",
      "      ┌►┌─└─ годы          obl\n",
      "      │ └──► учёбы         nmod\n",
      "┌───┌─└───── увлёкся       \n",
      "│   │     ┌► нелегальной   amod\n",
      "│ ┌►│     └─ народнической amod\n",
      "│ │ │   ┌──► и             cc\n",
      "│ │ │   │ ┌► марксистской  amod\n",
      "│ │ │ ┌►└─└─ литературой   nmod\n",
      "│ │ │ │   ┌► ,             punct\n",
      "│ │ └►│ ┌─└─ участвовал    conj\n",
      "│ │   │ │ ┌► в             case\n",
      "│ │   └─└►└─ работе        obl\n",
      "│ │   │ ┌──► подпольных    amod\n",
      "│ │   │ │ ┌► рабочих       amod\n",
      "│ └───└►└─└─ кружков       nmod\n",
      "└──────────► .             punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.sents[2].syntax.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3250aa",
   "metadata": {},
   "source": [
    "# Задание2: Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
    "Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
    "Способ 2. На основе моделей word2vec или Glove или fastText.\n",
    "Сравните качество полученных моделей.\n",
    "Для поиска наборов данных в поисковой системе можно "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb80d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ece3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccb4603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>site_url</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>muslims busted they stole millions in govt ben...</td>\n",
       "      <td>print they should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>muslims busted stole millions govt benefits</td>\n",
       "      <td>print pay back money plus interest entire fami...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>re why did attorney general loretta lynch plea...</td>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>attorney general loretta lynch plead fifth</td>\n",
       "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>breaking weiner cooperating with fbi on hillar...</td>\n",
       "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
       "      <td>red state fox news sunday reported morning ant...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
       "      <td>email kayla mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
       "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>fantastic trumps  point plan to reform healthc...</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>fantastic trumps point plan reform healthcare ...</td>\n",
       "      <td>email healthcare reform make america great sin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  muslims busted they stole millions in govt ben...   \n",
       "1  re why did attorney general loretta lynch plea...   \n",
       "2  breaking weiner cooperating with fbi on hillar...   \n",
       "3  pin drop speech by father of daughter kidnappe...   \n",
       "4  fantastic trumps  point plan to reform healthc...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  print they should pay all the back all the mon...  english   \n",
       "1  why did attorney general loretta lynch plead t...  english   \n",
       "2  red state  \\nfox news sunday reported this mor...  english   \n",
       "3  email kayla mueller was a prisoner and torture...  english   \n",
       "4  email healthcare reform to make america great ...  english   \n",
       "\n",
       "              site_url                                       main_img_url  \\\n",
       "0  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "1  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "2  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "3  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
       "4  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
       "\n",
       "   type label                            title_without_stopwords  \\\n",
       "0  bias  Real        muslims busted stole millions govt benefits   \n",
       "1  bias  Real         attorney general loretta lynch plead fifth   \n",
       "2  bias  Real  breaking weiner cooperating fbi hillary email ...   \n",
       "3  bias  Real  pin drop speech father daughter kidnapped kill...   \n",
       "4  bias  Real  fantastic trumps point plan reform healthcare ...   \n",
       "\n",
       "                              text_without_stopwords  hasImage  \n",
       "0  print pay back money plus interest entire fami...       1.0  \n",
       "1  attorney general loretta lynch plead fifth bar...       1.0  \n",
       "2  red state fox news sunday reported morning ant...       1.0  \n",
       "3  email kayla mueller prisoner tortured isis cha...       1.0  \n",
       "4  email healthcare reform make america great sin...       1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"news_articles.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84e4049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>print they should pay all the back all the mon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email kayla mueller was a prisoner and torture...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hasImage\n",
       "0  print they should pay all the back all the mon...       1.0\n",
       "1  why did attorney general loretta lynch plead t...       1.0\n",
       "2  red state  \\nfox news sunday reported this mor...       1.0\n",
       "3  email kayla mueller was a prisoner and torture...       1.0\n",
       "4  email healthcare reform to make america great ...       1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1=dataset[['text','hasImage']]\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b9412d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>print they should pay all the back all the mon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email kayla mueller was a prisoner and torture...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hasImage\n",
       "0  print they should pay all the back all the mon...       1.0\n",
       "1  why did attorney general loretta lynch plead t...       1.0\n",
       "2  red state  \\nfox news sunday reported this mor...       1.0\n",
       "3  email kayla mueller was a prisoner and torture...       1.0\n",
       "4  email healthcare reform to make america great ...       1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1=dataset1.dropna()\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdda8b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>by sarah jones on sat oct th  at  pm donald tr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>email \\n\\nhillary clinton personally ordered a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>by vin armani hillary clinton continues to bla...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>ignoring the law to rig elections democrats ar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>email president barack obama admonished donald...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  hasImage\n",
       "1397  by sarah jones on sat oct th  at  pm donald tr...       1.0\n",
       "492   email \\n\\nhillary clinton personally ordered a...       1.0\n",
       "237   by vin armani hillary clinton continues to bla...       0.0\n",
       "1178  ignoring the law to rig elections democrats ar...       1.0\n",
       "516   email president barack obama admonished donald...       1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1=dataset1.sample(frac=1)\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dc4f216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.772683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.419201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hasImage\n",
       "count  2050.000000\n",
       "mean      0.772683\n",
       "std       0.419201\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed3dbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=(dataset1.iloc[0:1500,:])\n",
    "test_df=(dataset1.iloc[1500:2050,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2265ca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.779333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.414834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hasImage\n",
       "count  1500.000000\n",
       "mean      0.779333\n",
       "std       0.414834\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9e8f457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.754545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.430748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hasImage\n",
       "count  550.000000\n",
       "mean     0.754545\n",
       "std      0.430748\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ba17a",
   "metadata": {},
   "source": [
    "# Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
    "Сформируем общий словарь для обучения моделей из обучающей и тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1a96bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email \\n\\nhillary clinton personally ordered a consultant to use a nonprofit group to troll the trump campaign with a donald duck mascot according to the democratic operatives who say they arranged it with a nonprofit organization \\nwhen breitbart news washington political editor matthew boyle confronted mook about creamer and his firm in the spin room after the third presidential debate mook claimed theyve never worked for our campaign when asked if clinton had ever discussed the controversial political operations with creamer directly mook replied i dont think so \\nnow however okeefe and project veritas have released video of creamer claiming that clinton directly approved one of his more bizarre plans  an effort to attract media attention and incite violence by dressing an activist in a donald duck costume and sending that activist into trump events emphasizing the argument that trump was ducking releasing his tax returns \\nthe action if true would be a blackletter violation of federal election law which prohibits presidential campaigns from coordinating activities with outside groups that can collect unlimited dark money from contributors  and dont pay taxes on what they collect \\nproject veritas action video footage shows robert creamer a convicted felon who was forced out of his executive role at the liberal consultancy democracy partners saying clinton chose the duck stunt \\nin the end it was the candidate hillary clinton the future president of the united states who wanted ducks on the ground so by god we would get ducks on the ground creamer says in the video',\n",
       " 'by vin armani hillary clinton continues to blame russia for the email leak even though it doesnt matter who leaked the damning emails if they',\n",
       " 'ignoring the law to rig elections democrats are fine with breaking the law as long as they benefit infowars nightly news  october   comments \\nimmigration laws are being ignored to an unprecedented extent \\nthe democrats are worried about russia interfering with our elections but are ignoring the law being broken and domestic interference via illegal immigrants newsletter sign up get the latest breaking news  specials from alex jones and the infowars crew related articles download on your mobile device now for free today on the show get the latest breaking news  specials from alex jones and the infowars crew from the store expert trump has already won election  see the rest on the alex jones youtube channel  the most offensive halloween ever  see the rest on the alex jones youtube channel  illustration how much will your healthcare premiums rise in     infowarscom is a free speech systems llc company all rights reserved digital millennium copyright act notice   flip the switch and supercharge your state of mind with brain force the next generation of neural activation from infowars life httpwwwinfowarscomwpcontentuploadsbrainforceejpg httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce brain force   off   flip the switch and supercharge your state of mind with brain force the next generation of neural activation from infowars life httpwwwinfowarscomwpcontentuploadsbrainforceejpg httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce brain force   off   flip the switch and supercharge your state of mind with brain force the next generation of neural activation from infowars life httpwwwinfowarscomwpcontentuploadsbrainforceejpg httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce brain force   off   flip the switch and supercharge your state of mind with brain force the next generation of neural activation from infowars life httpwwwinfowarscomwpcontentuploadsbrainforceejpg httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce brain force   off   flip the switch and supercharge your state of mind with brain force the next generation of neural activation from infowars life httpwwwinfowarscomwpcontentuploadsbrainforceejpg httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce brain force   off   flip the switch and supercharge your state of mind with brain force the next generation of neural activation from infowars life httpwwwinfowarscomwpcontentuploadsbrainforceejpg httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm_campaigninfowarsplacementutm_sourceinfowarscomutm_mediumwidgetutm_contentbrainforce',\n",
       " 'email president barack obama admonished donald trump thursday saying the republican nominees claims that he might not accept the results of next months election are not a joking matter i want everybody to pay attention here this is dangerous obama said at a hillary for america event in miami gardens florida because when you try to sow the seeds of doubt in peoples mind about the legitimacy of our elections that undermines our democracy then you are doing the work of our adversaries for them obama also encouraged the crowd of about  at florida memorial university to take advantage of floridas early voting telling the audience in doing so they can reject what the president called trumps dark pessimistic fearmongering our democracy depends on people knowing that their vote matters that those who occupy the seats of power were chosen by the people obama said on wednesday nights debate trump answered i will look at it at the time when asked whether he would concede if he loses on november  i will keep you in suspense trump also doubled down on thursday in ohio saying he will accept the results of next months election as long as wins obama also used the opportunity while in florida to weigh in on the close senate race in florida between republican sen marco rubio and his democratic challenger rep patrick murphy even marco rubio says theres no rigging of the vote obama said which id like to give credit for except hes refuting the dangerous unprecedented claims of a candidate he says hes still going to vote for earlier this week obama released a new ad for the democrat in the sunshine state the same week it was announced the democratic senatorial campaign committee was puling money for ads for murphy',\n",
       " 'david brock accused of elitist racism \\npaul joseph   a new email released as part of the wikileaks podesta dump features clinton ally brent budowsky accusing hillary operative david brock of having a plan that relied upon black voters being stupid the email  sent to clinton campaign chairman john podesta and another clinton ally ceo roy spence centers around a discussion of a bernie sanders campaign ad which featured many black faces back in january clinton operative david brock caused consternation within the campaign when he publicly claimed that bernie sanders didnt care about black people budowsky is not impressed with brocks outburst writing in the email brock makes the cardinal mistake of those who bring politics into disrepute with voters he tells a lie that people will know is a lie and insults the intelligence of black voters with a kind of elitist racism that bill and hillary clinton should not be seen with i guess brocks plan is that black voters are stupid and will not watch the ad and believe his lie writes budowsky i cannot think of anything more desperate more stupid and more selfdestructive than david brock lying about the bernie ad and playing a seamy brand of the politics of race using the tactic of deceit on her behalf adds the the hill and huffington post columnist before offering to write a campaign ad for hillary to counter the bernie sanders ad the email once again underscores the clinton camps paranoia about not being able to authentically connect with africanamerican voters in a way that bernie sanders could some black voters have been reluctant to support clinton as a result of her support for a  crime bill that resulted in the mass incarceration of young black americans whom hilary referred to at the time as super predators \\nsubscribe on youtube',\n",
       " 'by adalia woodbury on sun oct th  at  pm on friday the supreme court decided to weigh in on transgender rights in the case of gloucester county school board vs gg this gives the right wing another chance to take civil rights away from people they dont like plain and simple share on twitter print this post \\non friday the supreme court decided to weigh in on transgender rights in the case of gloucester county school board vs gg  this gives the right wing another chance to take civil rights away from people they dont like plain and simple \\nat issue is whether a transgender student who identifies as a boy has a right to use the bathroom that corresponds with the gender he identifies with \\nlast summer the court granted the school boards request to put a lower court ruling in the students favor on hold until the board filed its petition for review by the supreme court justice breyer joined the conservative justices in that ruling as a courtesy \\nthe virginia school board established a policy mirroring bathroom police laws in red states like north carolina that required students to use rest rooms and locker rooms to correspond with the gender they were assigned at birth \\nin this case the district court ruled against gg by relying on a  regulation allowing schools to provide separate toilet locker room and shower facilities based on sex provided those facilities are comparable to those provided to the opposite sex \\nin january  the department of educations office of civil rights issued a letter opining that if schools separate students in restroom and locker rooms based on their sex a school must treat transgender students in a manner consistent with their gender identity \\nbecause of that letter the us court of appeals for the th circuit reversed the lower court ruling in favor of gg it relied on a  supreme court decision that courts generally should defer to an agencys interpretation of its own regulation \\nin reality the right wing hopes to achieve two political objectives with this case first this is about denying basic rights and dignity to people who are transgender which is consistent with their ideological opposition to rights for women poc and members of the lgbt community second the right wing is hoping to weaken federal agencies by attacking their ability to interpret their own regulations',\n",
       " 'email \\nwell here we are gang \\nthis morning america woke up and found wed elected as president an overgrown bully a huckster without a drop of decency in his pizzadough body how the heck did we get here ill bet you wondered what the heck happened well theres a lot we dont know yet about this election but ill tell you this maybe you shouldnt have made fun of my exclamation point \\nyeah remember the exclamation point the big n red mark plopped next to my serifedup name like a trout on the counter we put that logo out and you people laughed oh how you laughed hey looks like ol wonder bread jebs trying to squeeze some enthusiasm out of his limp little campaign you think i didnt hear you you think i didnt see what you wrote of course i did the taunts the memes the novelty twitter handles typed with a sneer i saw all of it and it hurt me it hurt jeb \\nyou turned me and my exclamation mark into a big dippy joke and look what it got you dread defeat humiliation feel that despair in your gut today and now imagine if you had jeb in your life right now splashed across every tv and touchscreen hey theres some punctuation thatd put pep in your step but nope the guy who sticks his neck out to make electoral politics just a keystroke more exciting gets ribbed roasted raked over the coals and hung out to dry \\nlook i wasnt a perfect candidate i know that but that doesnt mean you had to steer this country straight into a xenophobic hellhole \\nthat exclamation point was plain fun it stood out from the pack it even looked nice on a tshirt or a coozy you made a huge mistake the moment you collectively decided to rip my exclamation point to shreds \\ni was up all night coming up with it you know that  was a john ellis bush original id already tried out a question mark too uncertain an ellipsis too ambiguous even two exclamation points too forceful so when i hit on the idea of an exclamation point i really thought i had something special i was so excited to share my excitement with you turns out i might as well have slapped my thick pink matte dick into my hand and waggled it all over facebook live like a dang date palm frond for all the love you gave me \\nlook i wasnt a perfect candidate i know that but that doesnt mean you had to steer this country straight into a xenophobic hellhole all you had to do was be nice about that exclamation point for a few months but you couldnt leave it alone could you you just could not resist having a good old laugh well take a look around and tell me what you see a divided nation headed for the falls with a dipshit at the helm belting out one last drunken shanty before it all goes to chunks and splinters you bullies deserve it all \\ngoodbye america i would have been delightful',\n",
       " 'ever wonder whats on the mind of todays most notable people well dont miss our unbelievable roundup of the best and most talked about quotes of the day  toads are dry and frogs are wet what more do i have to say  bindi irwin on telling frogs and toads apart  when i was in college i would sometimes run around campus and frantically shout for everyone to go to the river because someone was drowning it would really get peoples attention and wed all run to the river then in the middle of the river would be a big box with the word society written on the side of it that i had planted there id then look at everyone and go what are you going to do  moby on why he was kicked out of school  when i was a kid my father would point to our television and say son one day you are going to be inside of that thing telling everyone about the latest bruno mars dance  willie geist',\n",
       " 'as the election is inching slowly towards its end experts are nervously scrambling to find any dirt that would stop the trump train\\nfirst megyn kelly pulled the sexist card then it was his undisclosed tax returns then his comments on john mccain then making fun of crippled reporters then his reading of mein kampf then his remarks about dating his daughter\\nthen accusations of racism from former employees his usage of eminent domain hiring of immigrants and other questionable practices the trump university scandal his blunder on abortion old comments on drug decriminalization and gun control his relationship with the clintons and the dc insiders his comments on refugees and illegal immigrants the khan incident and of course the pussygrabbing scandal\\n\\nsurely this time it will sink his campaign wont it  and yet each time teflon don deflects dirt more dexterously than ghetto trash trying escape alimony payments nothing seems to be able to stop him not that his opponents will ever stop trying\\ntrump has the fantastic ability to escape unharmed from what would clearly destroy any career politician howard deans yeehaw was enough to end his bid for the democratic candidate in  and yet trump can call for an end to muslim refugees be accused of grabbing women by their loins and end up being praised for it by the masses while the mainstream media spew their bile \\n\\nwhat has allowed trump to maneuver so nimbly against these accusations is the unprecedented role of internet media in elections including being able to reach people directly through twitter and a lack of trust in traditional media as well as his biggerthanlife persona letting him get away with what others would be lynched for\\nbut thats the story for another article i would rather talk about something else particularly is there anything that could stop him the answer will surprise you as it goes against all conventional wisdom\\nyes but its not what you think\\ntrumps weak spot \\none of the biggest problems with defeating trump is that unlike other politicians political scandals not only seem to not affect him but they even aid him there is a saying that every antitrump meme is also a protrump meme\\n\\ntrump has mastered political antifragility which causes him to only strengthen when opponents try to destroy him trump has defeated the lefts no platform for fascists mentality by saying things so outrageous they have no option but to report on him\\nso the left cannot choose to not cover him and let him wallow in obscurity like they did with ron paul neither can they attack him for each of their attacks only make him more popular\\n\\none memorable movie quote i remember went something like this every man has a weak spot first you try to buy him with money then women then you go for his family and if that doesnt work well a bullet always does the job unfortunately unlike other political losers don does not need other peoples money nor does he lack female attention and his family is smart and probably safe from violence\\nbut this isnt an article about god forbid donald trump getting assassinated that would stop trump but not the trump train trump is more than a man trump is an idea he is the avatar of discontent of all those opposed to progressive ideology he would become a martyr thus raising the hatred for his opponents to a fever pitch which might alter americas consciousness forever trumps enemies cant afford that\\nso if ignoring trump does not work throwing dirt at him does not work bribing him doesnt work and even killing him wont work than what is left the answer might surprise you\\nyou see trumps power comes from his contrarianism he is not a candidate he is an anticandidate people dont just vote for trump they vote against hillary obama progressives and cuckservatives he is the wrecking ball who the injured working class and all nonliberal whites as well as minorities not completely in love in with progressive marxist ideology want to use against the establishment\\nso what can be done to stop him  \\nwell lets ask ourselves what makes trump popular  his brashness his antipc attitudes his antielitism his not being a part of the establishment hacks his being not one of them his being different\\nso if that is what gives trump strength it would make sense that to weaken him you would have to present him as the opposite of that to present him as being nothing special to make him look boring and weak to present him as just another pcdrone\\ntheyve claimed nonstop that trump is the next hitler and that he will start building concentration camps and sexually assaulting random women by grabbing their cock pockets and will obliterate muslims and minorities with right wing death squad robots\\n\\ninstead they could have claimed that he is just weakling trying to act tough and that he wont deliver anything that he is in love with political correctness and respects women that he is a progressives best choice that he will bring four more years of obama\\nthat of course would present its own difficulties in the age of online media the monopoly of physical press has been broken when news circulates at the speed of minutes rather than hours and days it would be very hard for the establishment media to accomplish this it is very hard to call trump ordinary and boring when his statements break so many taboos\\nyet as difficult as it may have been at the very least it would have had a chance of success as small as it was calling him sexist racist and other mean words did nothing to stop him and instead only made him more popular with the masses some of these incidents have made donald seem human and it made people trust him more showing his flaws had the opposite effect as intended as those who hated him already needed no extra ammo but those who liked him were either left indifferent or whats worse excited by his statements\\n\\nat worst a few moderates had doubts set in their mind however considering what short attention span undecided voters have his stellar performance at the second debate clearly made them forget about the statement and maybe even convinced them to focus on bills sexual misdeeds instead\\nwhy havent his opponents used this against him \\nthis brings us to the final point of this article why havent his opponents used this against him have they not the brains to figure this out hard to believe considering the amount of money being poured into think tanks\\nno the truth is like that the strategy was forsaken because of the sideeffects it would have on their own camp should his opponents try to attack him as another pc drone they would be also attacking themselves just like hillary trying to paint trump as sex offender only made it easier for trump to point at bills sexual indiscretions as it has been said in the mighty book of kek  thee that dwell in glass lodgings shall not propel sedimentary formations the prophecy of kek chapter   verse  \\n\\nattacking trump for being multicultural politically correct weak inefficient or a shill would only shed light on the establishments own weakness\\nthis means that in order to draw voters away from trump they would have to claim trump loves multiculturalism antiracism open borders free trade globalism and offer another candidate who would be even more extreme than him on these crucial issues\\n\\nusing this strategy against trump even if it was successful would be a pyrrhic victory for his opponents as cuckservatives would have to acknowledge they cant woo supporters with talks about reducing taxes and bringing back reaganism the truth is the future is bleak for reaganbushcuck wing of the gop even if they were to win the election they would lose the war\\n\\nthe left has won the cultural war not just by winning elections but by cultural metawarfare instead of moderating their message in attempt to win election they used popular culture and mass media to push liberal values to the masses and so the right wing had no option but do concessions dropping people who opposed civil rights womens liberation and closed borders\\nto put it simply the battle was lost even before trump cametrump was the match that ignited the powder keg he simply mobilized people and said what others kept in private but always wanted to say and now there is no turning back\\nthe elites cannot choose to ignore popular will and still win elections anymore they will have to reform the gop to account for their constituencys desire or risk ending in the dust bin of history there is no longer the option to charm the sheeple with talks about low taxes open borders and the awfulness of bigotry they will have to at least nominally give something back to the people to stay in power\\nas one wise commenter on this site once said  trump may be a liar like the rest of them but at least he is saying the right lies\\nthe next thing people on the manosphere and the altright will have to look after will be trumplike figures who will copy trumps rhetoric but will fail to deliver any solutions or they will try to coopt and redirect that anger but for now for the first time in more than  years we are winning the culture war \\nread more will the cruzsexscandal propel donald trump into the white house']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = train_df['text'].tolist()\n",
    "vocab_list[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5126a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, train_df['text'], train_df['hasImage'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67f8cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 40455\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(vocab_list)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88babaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'___': 0, 'aa': 1, 'aab': 2, 'aadmi': 3, 'aafe': 4,\n",
      "                            'aah': 5, 'aaja': 6, 'aali': 7, 'aam': 8, 'aand': 9,\n",
      "                            'aap': 10, 'aaps': 11, 'aaron': 12, 'aas': 13,\n",
      "                            'ab': 14, 'aba': 15, 'aback': 16, 'abajo': 17,\n",
      "                            'abandon': 18, 'abandoned': 19, 'abandoning': 20,\n",
      "                            'abandonment': 21, 'abandons': 22, 'abated': 23,\n",
      "                            'abb': 24, 'abbas': 25, 'abbasside': 26,\n",
      "                            'abbekommen': 27, 'abbey': 28, 'abbott': 29, ...})\n",
      "Модель для классификации - LogisticRegression()\n",
      "Accuracy = 0.7893333333333334\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'___': 0, 'aa': 1, 'aab': 2, 'aadmi': 3, 'aafe': 4,\n",
      "                            'aah': 5, 'aaja': 6, 'aali': 7, 'aam': 8, 'aand': 9,\n",
      "                            'aap': 10, 'aaps': 11, 'aaron': 12, 'aas': 13,\n",
      "                            'ab': 14, 'aba': 15, 'aback': 16, 'abajo': 17,\n",
      "                            'abandon': 18, 'abandoned': 19, 'abandoning': 20,\n",
      "                            'abandonment': 21, 'abandons': 22, 'abated': 23,\n",
      "                            'abb': 24, 'abbas': 25, 'abbasside': 26,\n",
      "                            'abbekommen': 27, 'abbey': 28, 'abbott': 29, ...})\n",
      "Модель для классификации - MultinomialNB()\n",
      "Accuracy = 0.7766666666666667\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'___': 0, 'aa': 1, 'aab': 2, 'aadmi': 3, 'aafe': 4,\n",
      "                            'aah': 5, 'aaja': 6, 'aali': 7, 'aam': 8, 'aand': 9,\n",
      "                            'aap': 10, 'aaps': 11, 'aaron': 12, 'aas': 13,\n",
      "                            'ab': 14, 'aba': 15, 'aback': 16, 'abajo': 17,\n",
      "                            'abandon': 18, 'abandoned': 19, 'abandoning': 20,\n",
      "                            'abandonment': 21, 'abandons': 22, 'abated': 23,\n",
      "                            'abb': 24, 'abbas': 25, 'abbasside': 26,\n",
      "                            'abbekommen': 27, 'abbey': 28, 'abbott': 29, ...})\n",
      "Модель для классификации - LogisticRegression()\n",
      "Accuracy = 0.7840000000000001\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'___': 0, 'aa': 1, 'aab': 2, 'aadmi': 3, 'aafe': 4,\n",
      "                            'aah': 5, 'aaja': 6, 'aali': 7, 'aam': 8, 'aand': 9,\n",
      "                            'aap': 10, 'aaps': 11, 'aaron': 12, 'aas': 13,\n",
      "                            'ab': 14, 'aba': 15, 'aback': 16, 'abajo': 17,\n",
      "                            'abandon': 18, 'abandoned': 19, 'abandoning': 20,\n",
      "                            'abandonment': 21, 'abandons': 22, 'abated': 23,\n",
      "                            'abb': 24, 'abbas': 25, 'abbasside': 26,\n",
      "                            'abbekommen': 27, 'abbey': 28, 'abbott': 29, ...})\n",
      "Модель для классификации - MultinomialNB()\n",
      "Accuracy = 0.7793333333333333\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(), MultinomialNB()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba41295",
   "metadata": {},
   "source": [
    "Лучшую точность показал CountVectorizer и LogisticRegression(78.93%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e2a4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df['text']\n",
    "y_train=train_df['hasImage']\n",
    "X_test=test_df['text']\n",
    "y_test=test_df['hasImage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4baceb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eab316a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0.0 \t 0.5259259259259259\n",
      "1.0 \t 0.9132530120481928\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), LogisticRegression(C=5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad76f81",
   "metadata": {},
   "source": [
    "# Способ 2. На основе моделей word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad810ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12391\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaffc5e",
   "metadata": {},
   "source": [
    "Подготовим корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "752ed6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "stop_words = stopwords.words('english')\n",
    "tok = WordPunctTokenizer()\n",
    "for line in dataset1['text'].values:\n",
    "    line1 = line.strip().lower()\n",
    "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
    "    text_tok = tok.tokenize(line1)\n",
    "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
    "    corpus.append(text_tok1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "602c0323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sarah',\n",
       "  'jones',\n",
       "  'sat',\n",
       "  'oct',\n",
       "  'th',\n",
       "  'pm',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'uses',\n",
       "  'sexual',\n",
       "  'shaming',\n",
       "  'humiliation',\n",
       "  'women',\n",
       "  'simplistic',\n",
       "  'revenge',\n",
       "  'slightest',\n",
       "  'felt',\n",
       "  'spurn',\n",
       "  'newly',\n",
       "  'surfaced',\n",
       "  'video',\n",
       "  'via',\n",
       "  'ryan',\n",
       "  'grim',\n",
       "  'shows',\n",
       "  'trump',\n",
       "  'humiliation',\n",
       "  'game',\n",
       "  'action',\n",
       "  'walk',\n",
       "  'everyone',\n",
       "  'pov',\n",
       "  'woman',\n",
       "  'share',\n",
       "  'twitter',\n",
       "  'print',\n",
       "  'post',\n",
       "  'youre',\n",
       "  'woman',\n",
       "  'whos',\n",
       "  'worked',\n",
       "  'business',\n",
       "  'youre',\n",
       "  'forced',\n",
       "  'try',\n",
       "  'appease',\n",
       "  'massively',\n",
       "  'sensitive',\n",
       "  'ego',\n",
       "  'sexually',\n",
       "  'aggressive',\n",
       "  'vulgar',\n",
       "  'man',\n",
       "  'power',\n",
       "  'know',\n",
       "  'exactly',\n",
       "  'whats',\n",
       "  'happen',\n",
       "  'video',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'uses',\n",
       "  'sexual',\n",
       "  'shaming',\n",
       "  'humiliation',\n",
       "  'women',\n",
       "  'simplistic',\n",
       "  'revenge',\n",
       "  'slightest',\n",
       "  'felt',\n",
       "  'spurn',\n",
       "  'theres',\n",
       "  'newly',\n",
       "  'surfaced',\n",
       "  'video',\n",
       "  'via',\n",
       "  'ryan',\n",
       "  'grim',\n",
       "  'huffington',\n",
       "  'post',\n",
       "  'shows',\n",
       "  'trump',\n",
       "  'humiliation',\n",
       "  'game',\n",
       "  'action',\n",
       "  'video',\n",
       "  'trump',\n",
       "  'publicly',\n",
       "  'sexualizes',\n",
       "  'shames',\n",
       "  'miss',\n",
       "  'universe',\n",
       "  'winner',\n",
       "  'australia',\n",
       "  'jennifer',\n",
       "  'hawkins',\n",
       "  'revenge',\n",
       "  'trump',\n",
       "  'tells',\n",
       "  'audience',\n",
       "  'get',\n",
       "  'even',\n",
       "  'people',\n",
       "  'screw',\n",
       "  'screw',\n",
       "  'back',\n",
       "  'times',\n",
       "  'hard',\n",
       "  'really',\n",
       "  'believe',\n",
       "  'watch',\n",
       "  'newly',\n",
       "  'surfaced',\n",
       "  'corporate',\n",
       "  'speech',\n",
       "  'via',\n",
       "  'huffington',\n",
       "  'post',\n",
       "  'major',\n",
       "  'trigger',\n",
       "  'warning',\n",
       "  'youve',\n",
       "  'watching',\n",
       "  'see',\n",
       "  'trump',\n",
       "  'modus',\n",
       "  'operandi',\n",
       "  'action',\n",
       "  'sting',\n",
       "  'felt',\n",
       "  'numerous',\n",
       "  'women',\n",
       "  'report',\n",
       "  'spurning',\n",
       "  'trumps',\n",
       "  'advances',\n",
       "  'harassment',\n",
       "  'revenge',\n",
       "  'sexual',\n",
       "  'shaming',\n",
       "  'trump',\n",
       "  'sets',\n",
       "  'audience',\n",
       "  'roman',\n",
       "  'gladiator',\n",
       "  'moment',\n",
       "  'public',\n",
       "  'sexual',\n",
       "  'offering',\n",
       "  'priming',\n",
       "  'belief',\n",
       "  'screw',\n",
       "  'people',\n",
       "  'back',\n",
       "  'screw',\n",
       "  'sexually',\n",
       "  'angry',\n",
       "  'verb',\n",
       "  'foreshadows',\n",
       "  'whats',\n",
       "  'come',\n",
       "  'going',\n",
       "  'screw',\n",
       "  'jennifer',\n",
       "  'hawkins',\n",
       "  'public',\n",
       "  'realizes',\n",
       "  'public',\n",
       "  'cant',\n",
       "  'humiliate',\n",
       "  'saying',\n",
       "  'objecting',\n",
       "  'without',\n",
       "  'facing',\n",
       "  'huge',\n",
       "  'repercussions',\n",
       "  'trump',\n",
       "  'says',\n",
       "  'hes',\n",
       "  'going',\n",
       "  'give',\n",
       "  'example',\n",
       "  'revenge',\n",
       "  'theory',\n",
       "  'jennifer',\n",
       "  'hawkins',\n",
       "  'trump',\n",
       "  'orders',\n",
       "  'hawkins',\n",
       "  'stage',\n",
       "  'audience',\n",
       "  'cheers',\n",
       "  'jeers',\n",
       "  'delighting',\n",
       "  'upcoming',\n",
       "  'shaming',\n",
       "  'beautiful',\n",
       "  'girl',\n",
       "  'public',\n",
       "  'spanking',\n",
       "  'much',\n",
       "  'fun',\n",
       "  'first',\n",
       "  'beautiful',\n",
       "  'jennifer',\n",
       "  'trump',\n",
       "  'asks',\n",
       "  'claiming',\n",
       "  'ownership',\n",
       "  'jennifer',\n",
       "  'object',\n",
       "  'playing',\n",
       "  'magnanimous',\n",
       "  'daddy',\n",
       "  'dishes',\n",
       "  'praise',\n",
       "  'approval',\n",
       "  'spanking',\n",
       "  'message',\n",
       "  'make',\n",
       "  'break',\n",
       "  'better',\n",
       "  'play',\n",
       "  'nice',\n",
       "  'warning',\n",
       "  'shot',\n",
       "  'getting',\n",
       "  'even',\n",
       "  'trump',\n",
       "  'tells',\n",
       "  'audience',\n",
       "  'mad',\n",
       "  'hawkins',\n",
       "  'allegedly',\n",
       "  'dissed',\n",
       "  'declining',\n",
       "  'introduce',\n",
       "  'event',\n",
       "  'sydney',\n",
       "  'tells',\n",
       "  'audience',\n",
       "  'mad',\n",
       "  'says',\n",
       "  'shes',\n",
       "  'crossing',\n",
       "  'stage',\n",
       "  'shes',\n",
       "  'favorite',\n",
       "  'miss',\n",
       "  'universe',\n",
       "  'thinks',\n",
       "  'maybe',\n",
       "  'isnt',\n",
       "  'going',\n",
       "  'bad',\n",
       "  'fears',\n",
       "  'stabs',\n",
       "  'publicly',\n",
       "  'first',\n",
       "  'time',\n",
       "  'think',\n",
       "  'like',\n",
       "  'new',\n",
       "  'one',\n",
       "  'better',\n",
       "  'audience',\n",
       "  'loves',\n",
       "  'going',\n",
       "  'feed',\n",
       "  'sexual',\n",
       "  'humiliation',\n",
       "  'beautiful',\n",
       "  'woman',\n",
       "  'wasnt',\n",
       "  'good',\n",
       "  'girl',\n",
       "  'reaches',\n",
       "  'clasp',\n",
       "  'hands',\n",
       "  'smiles',\n",
       "  'shame',\n",
       "  'knowing',\n",
       "  'choice',\n",
       "  'wanting',\n",
       "  'good',\n",
       "  'sport',\n",
       "  'hawkins',\n",
       "  'tries',\n",
       "  'make',\n",
       "  'light',\n",
       "  'situation',\n",
       "  'appeasing',\n",
       "  'trump',\n",
       "  'playing',\n",
       "  'along',\n",
       "  'game',\n",
       "  'easy',\n",
       "  'way',\n",
       "  'one',\n",
       "  'wont',\n",
       "  'enough',\n",
       "  'fawn',\n",
       "  'front',\n",
       "  'audience',\n",
       "  'pay',\n",
       "  'actually',\n",
       "  'going',\n",
       "  'get',\n",
       "  'tell',\n",
       "  'jennifer',\n",
       "  'beautiful',\n",
       "  'girl',\n",
       "  'outside',\n",
       "  'shes',\n",
       "  'bright',\n",
       "  'trump',\n",
       "  'tells',\n",
       "  'audience',\n",
       "  'signaling',\n",
       "  'hawkins',\n",
       "  'piece',\n",
       "  'meat',\n",
       "  'dissected',\n",
       "  'publicly',\n",
       "  'refusal',\n",
       "  'give',\n",
       "  'anything',\n",
       "  'asks',\n",
       "  'wouldnt',\n",
       "  'true',\n",
       "  'would',\n",
       "  'said',\n",
       "  'anyway',\n",
       "  'trump',\n",
       "  'proudly',\n",
       "  'tells',\n",
       "  'audience',\n",
       "  'alpha',\n",
       "  'male',\n",
       "  'routine',\n",
       "  'except',\n",
       "  'real',\n",
       "  'life',\n",
       "  'alpha',\n",
       "  'male',\n",
       "  'doesnt',\n",
       "  'abuse',\n",
       "  'money',\n",
       "  'power',\n",
       "  'inherited',\n",
       "  'order',\n",
       "  'win',\n",
       "  'girl',\n",
       "  'mind',\n",
       "  'little',\n",
       "  'men',\n",
       "  'like',\n",
       "  'trump',\n",
       "  'makes',\n",
       "  'winner',\n",
       "  'trump',\n",
       "  'points',\n",
       "  'hawkins',\n",
       "  'big',\n",
       "  'star',\n",
       "  'helped',\n",
       "  'make',\n",
       "  'dissed',\n",
       "  'owns',\n",
       "  'must',\n",
       "  'comply',\n",
       "  'face',\n",
       "  'wrath',\n",
       "  'hawkins',\n",
       "  'tries',\n",
       "  'say',\n",
       "  'introduce',\n",
       "  'trump',\n",
       "  'pushes',\n",
       "  'away',\n",
       "  'microphone',\n",
       "  'public',\n",
       "  'shaming',\n",
       "  'done',\n",
       "  'trumps',\n",
       "  'pov',\n",
       "  'need',\n",
       "  'hawkins',\n",
       "  'assert',\n",
       "  'personhoodthere',\n",
       "  'defense',\n",
       "  'allowed',\n",
       "  'shes',\n",
       "  'already',\n",
       "  'guilty',\n",
       "  'know',\n",
       "  'came',\n",
       "  'tonight',\n",
       "  'came',\n",
       "  'came',\n",
       "  'came',\n",
       "  'came',\n",
       "  'trump',\n",
       "  'says',\n",
       "  'gleefully',\n",
       "  'like',\n",
       "  'drunk',\n",
       "  'pervy',\n",
       "  'uncle',\n",
       "  'everyone',\n",
       "  'tries',\n",
       "  'avoid',\n",
       "  'christmas',\n",
       "  'waits',\n",
       "  'audience',\n",
       "  'join',\n",
       "  'sexual',\n",
       "  'shaming',\n",
       "  'get',\n",
       "  'hee',\n",
       "  'heee',\n",
       "  'clever',\n",
       "  'came',\n",
       "  'knuckles',\n",
       "  'dragging',\n",
       "  'floor',\n",
       "  'clever',\n",
       "  'see',\n",
       "  'filthy',\n",
       "  'minds',\n",
       "  'australia',\n",
       "  'trump',\n",
       "  'says',\n",
       "  'trump',\n",
       "  'grabs',\n",
       "  'hawkins',\n",
       "  'around',\n",
       "  'waist',\n",
       "  'forces',\n",
       "  'kiss',\n",
       "  'like',\n",
       "  'bragged',\n",
       "  'bush',\n",
       "  'tape',\n",
       "  'hawkins',\n",
       "  'reflexively',\n",
       "  'turns',\n",
       "  'away',\n",
       "  'puts',\n",
       "  'arm',\n",
       "  'kiss',\n",
       "  'misses',\n",
       "  'mark',\n",
       "  'lands',\n",
       "  'cheek',\n",
       "  'hoping',\n",
       "  'good',\n",
       "  'enough',\n",
       "  'humiliation',\n",
       "  'putting',\n",
       "  'foot',\n",
       "  'actual',\n",
       "  'mouth',\n",
       "  'contact',\n",
       "  'shes',\n",
       "  'allowed',\n",
       "  'publicly',\n",
       "  'humiliated',\n",
       "  'appease',\n",
       "  'pretended',\n",
       "  'fawn',\n",
       "  'required',\n",
       "  'cannot',\n",
       "  'allow',\n",
       "  'kiss',\n",
       "  'repulsive',\n",
       "  'kiss',\n",
       "  'im',\n",
       "  'telling',\n",
       "  'story',\n",
       "  'imagine',\n",
       "  'point',\n",
       "  'view',\n",
       "  'although',\n",
       "  'refused',\n",
       "  'comment',\n",
       "  'course',\n",
       "  'refused',\n",
       "  'comment',\n",
       "  'women',\n",
       "  'told',\n",
       "  'blackballed',\n",
       "  'comment',\n",
       "  'world',\n",
       "  'full',\n",
       "  'men',\n",
       "  'like',\n",
       "  'trump',\n",
       "  'stick',\n",
       "  'together',\n",
       "  'see',\n",
       "  'roger',\n",
       "  'ailes',\n",
       "  'women',\n",
       "  'play',\n",
       "  'along',\n",
       "  'appease',\n",
       "  'doesnt',\n",
       "  'work',\n",
       "  'allow',\n",
       "  'sexually',\n",
       "  'assaulted',\n",
       "  'humiliated',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'public',\n",
       "  'especially',\n",
       "  'said',\n",
       "  'private',\n",
       "  'lived',\n",
       "  'somewhat',\n",
       "  'like',\n",
       "  'public',\n",
       "  'tried',\n",
       "  'appease',\n",
       "  'ego',\n",
       "  'assaulter',\n",
       "  'order',\n",
       "  'keep',\n",
       "  'job',\n",
       "  'denying',\n",
       "  'assumed',\n",
       "  'entitlement',\n",
       "  'body',\n",
       "  'talking',\n",
       "  'many',\n",
       "  'women',\n",
       "  'election',\n",
       "  'know',\n",
       "  'im',\n",
       "  'alone',\n",
       "  'know',\n",
       "  'many',\n",
       "  'women',\n",
       "  'watch',\n",
       "  'know',\n",
       "  'feel',\n",
       "  'creep',\n",
       "  'fear',\n",
       "  'revulsion',\n",
       "  'deer',\n",
       "  'headlights',\n",
       "  'cringe',\n",
       "  'takes',\n",
       "  'know',\n",
       "  'humiliated',\n",
       "  'sexual',\n",
       "  'object',\n",
       "  'refused',\n",
       "  'refused',\n",
       "  'appease',\n",
       "  'ego',\n",
       "  'powerful',\n",
       "  'man',\n",
       "  'charge',\n",
       "  'behaving',\n",
       "  'like',\n",
       "  'sexual',\n",
       "  'conquest',\n",
       "  'dare',\n",
       "  'hawkins',\n",
       "  'life',\n",
       "  'unwilling',\n",
       "  'change',\n",
       "  'plans',\n",
       "  'order',\n",
       "  'introduce',\n",
       "  'trump',\n",
       "  'people',\n",
       "  'watch',\n",
       "  'humiliation',\n",
       "  'enjoy',\n",
       "  'setting',\n",
       "  'humiliated',\n",
       "  'even',\n",
       "  'laugh',\n",
       "  'gossip',\n",
       "  'social',\n",
       "  'punishment',\n",
       "  'women',\n",
       "  'face',\n",
       "  'reject',\n",
       "  'man',\n",
       "  'like',\n",
       "  'trump',\n",
       "  'ironically',\n",
       "  'give',\n",
       "  'youre',\n",
       "  'humiliated',\n",
       "  'say',\n",
       "  'set',\n",
       "  'publicly',\n",
       "  'flogged',\n",
       "  'sex',\n",
       "  'object',\n",
       "  'unwanted',\n",
       "  'kiss',\n",
       "  'although',\n",
       "  'disgusting',\n",
       "  'assault',\n",
       "  'much',\n",
       "  'like',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'bragged',\n",
       "  'billy',\n",
       "  'bush',\n",
       "  'bus',\n",
       "  'tape',\n",
       "  'public',\n",
       "  'humiliation',\n",
       "  'denigration',\n",
       "  'way',\n",
       "  'woman',\n",
       "  'forced',\n",
       "  'front',\n",
       "  'thousands',\n",
       "  'people',\n",
       "  'try',\n",
       "  'smile',\n",
       "  'way',\n",
       "  'ambush',\n",
       "  'verbal',\n",
       "  'physical',\n",
       "  'assaults',\n",
       "  'takes',\n",
       "  'revenge',\n",
       "  'way',\n",
       "  'tries',\n",
       "  'make',\n",
       "  'okay',\n",
       "  'sweetsmooth',\n",
       "  'ego',\n",
       "  'order',\n",
       "  'get',\n",
       "  'line',\n",
       "  'fire',\n",
       "  'return',\n",
       "  'shames',\n",
       "  'suggesting',\n",
       "  'made',\n",
       "  'come',\n",
       "  'grabs',\n",
       "  'unwanted',\n",
       "  'kiss',\n",
       "  'good',\n",
       "  'come',\n",
       "  'total',\n",
       "  'crapfest',\n",
       "  'trump',\n",
       "  'candidacy',\n",
       "  'perhaps',\n",
       "  'raised',\n",
       "  'awareness',\n",
       "  'women',\n",
       "  'people',\n",
       "  'kind',\n",
       "  'thing',\n",
       "  'horrific',\n",
       "  'trumps',\n",
       "  'fault',\n",
       "  'cultures',\n",
       "  'fault',\n",
       "  'takes',\n",
       "  'willing',\n",
       "  'audience',\n",
       "  'successfully',\n",
       "  'publicly',\n",
       "  'sexually',\n",
       "  'shame',\n",
       "  'woman',\n",
       "  'fact',\n",
       "  'shades',\n",
       "  'trump',\n",
       "  'hillary',\n",
       "  'clinton',\n",
       "  'stalking',\n",
       "  'debate',\n",
       "  'announced',\n",
       "  'looking',\n",
       "  'behind',\n",
       "  'impressed',\n",
       "  'neither',\n",
       "  'mr',\n",
       "  'trump',\n",
       "  'neither'],\n",
       " ['email',\n",
       "  'hillary',\n",
       "  'clinton',\n",
       "  'personally',\n",
       "  'ordered',\n",
       "  'consultant',\n",
       "  'use',\n",
       "  'nonprofit',\n",
       "  'group',\n",
       "  'troll',\n",
       "  'trump',\n",
       "  'campaign',\n",
       "  'donald',\n",
       "  'duck',\n",
       "  'mascot',\n",
       "  'according',\n",
       "  'democratic',\n",
       "  'operatives',\n",
       "  'say',\n",
       "  'arranged',\n",
       "  'nonprofit',\n",
       "  'organization',\n",
       "  'breitbart',\n",
       "  'news',\n",
       "  'washington',\n",
       "  'political',\n",
       "  'editor',\n",
       "  'matthew',\n",
       "  'boyle',\n",
       "  'confronted',\n",
       "  'mook',\n",
       "  'creamer',\n",
       "  'firm',\n",
       "  'spin',\n",
       "  'room',\n",
       "  'third',\n",
       "  'presidential',\n",
       "  'debate',\n",
       "  'mook',\n",
       "  'claimed',\n",
       "  'theyve',\n",
       "  'never',\n",
       "  'worked',\n",
       "  'campaign',\n",
       "  'asked',\n",
       "  'clinton',\n",
       "  'ever',\n",
       "  'discussed',\n",
       "  'controversial',\n",
       "  'political',\n",
       "  'operations',\n",
       "  'creamer',\n",
       "  'directly',\n",
       "  'mook',\n",
       "  'replied',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'however',\n",
       "  'okeefe',\n",
       "  'project',\n",
       "  'veritas',\n",
       "  'released',\n",
       "  'video',\n",
       "  'creamer',\n",
       "  'claiming',\n",
       "  'clinton',\n",
       "  'directly',\n",
       "  'approved',\n",
       "  'one',\n",
       "  'bizarre',\n",
       "  'plans',\n",
       "  'effort',\n",
       "  'attract',\n",
       "  'media',\n",
       "  'attention',\n",
       "  'incite',\n",
       "  'violence',\n",
       "  'dressing',\n",
       "  'activist',\n",
       "  'donald',\n",
       "  'duck',\n",
       "  'costume',\n",
       "  'sending',\n",
       "  'activist',\n",
       "  'trump',\n",
       "  'events',\n",
       "  'emphasizing',\n",
       "  'argument',\n",
       "  'trump',\n",
       "  'ducking',\n",
       "  'releasing',\n",
       "  'tax',\n",
       "  'returns',\n",
       "  'action',\n",
       "  'true',\n",
       "  'would',\n",
       "  'blackletter',\n",
       "  'violation',\n",
       "  'federal',\n",
       "  'election',\n",
       "  'law',\n",
       "  'prohibits',\n",
       "  'presidential',\n",
       "  'campaigns',\n",
       "  'coordinating',\n",
       "  'activities',\n",
       "  'outside',\n",
       "  'groups',\n",
       "  'collect',\n",
       "  'unlimited',\n",
       "  'dark',\n",
       "  'money',\n",
       "  'contributors',\n",
       "  'dont',\n",
       "  'pay',\n",
       "  'taxes',\n",
       "  'collect',\n",
       "  'project',\n",
       "  'veritas',\n",
       "  'action',\n",
       "  'video',\n",
       "  'footage',\n",
       "  'shows',\n",
       "  'robert',\n",
       "  'creamer',\n",
       "  'convicted',\n",
       "  'felon',\n",
       "  'forced',\n",
       "  'executive',\n",
       "  'role',\n",
       "  'liberal',\n",
       "  'consultancy',\n",
       "  'democracy',\n",
       "  'partners',\n",
       "  'saying',\n",
       "  'clinton',\n",
       "  'chose',\n",
       "  'duck',\n",
       "  'stunt',\n",
       "  'end',\n",
       "  'candidate',\n",
       "  'hillary',\n",
       "  'clinton',\n",
       "  'future',\n",
       "  'president',\n",
       "  'united',\n",
       "  'states',\n",
       "  'wanted',\n",
       "  'ducks',\n",
       "  'ground',\n",
       "  'god',\n",
       "  'would',\n",
       "  'get',\n",
       "  'ducks',\n",
       "  'ground',\n",
       "  'creamer',\n",
       "  'says',\n",
       "  'video'],\n",
       " ['vin',\n",
       "  'armani',\n",
       "  'hillary',\n",
       "  'clinton',\n",
       "  'continues',\n",
       "  'blame',\n",
       "  'russia',\n",
       "  'email',\n",
       "  'leak',\n",
       "  'even',\n",
       "  'though',\n",
       "  'doesnt',\n",
       "  'matter',\n",
       "  'leaked',\n",
       "  'damning',\n",
       "  'emails'],\n",
       " ['ignoring',\n",
       "  'law',\n",
       "  'rig',\n",
       "  'elections',\n",
       "  'democrats',\n",
       "  'fine',\n",
       "  'breaking',\n",
       "  'law',\n",
       "  'long',\n",
       "  'benefit',\n",
       "  'infowars',\n",
       "  'nightly',\n",
       "  'news',\n",
       "  'october',\n",
       "  'comments',\n",
       "  'immigration',\n",
       "  'laws',\n",
       "  'ignored',\n",
       "  'unprecedented',\n",
       "  'extent',\n",
       "  'democrats',\n",
       "  'worried',\n",
       "  'russia',\n",
       "  'interfering',\n",
       "  'elections',\n",
       "  'ignoring',\n",
       "  'law',\n",
       "  'broken',\n",
       "  'domestic',\n",
       "  'interference',\n",
       "  'via',\n",
       "  'illegal',\n",
       "  'immigrants',\n",
       "  'newsletter',\n",
       "  'sign',\n",
       "  'get',\n",
       "  'latest',\n",
       "  'breaking',\n",
       "  'news',\n",
       "  'specials',\n",
       "  'alex',\n",
       "  'jones',\n",
       "  'infowars',\n",
       "  'crew',\n",
       "  'related',\n",
       "  'articles',\n",
       "  'download',\n",
       "  'mobile',\n",
       "  'device',\n",
       "  'free',\n",
       "  'today',\n",
       "  'show',\n",
       "  'get',\n",
       "  'latest',\n",
       "  'breaking',\n",
       "  'news',\n",
       "  'specials',\n",
       "  'alex',\n",
       "  'jones',\n",
       "  'infowars',\n",
       "  'crew',\n",
       "  'store',\n",
       "  'expert',\n",
       "  'trump',\n",
       "  'already',\n",
       "  'election',\n",
       "  'see',\n",
       "  'rest',\n",
       "  'alex',\n",
       "  'jones',\n",
       "  'youtube',\n",
       "  'channel',\n",
       "  'offensive',\n",
       "  'halloween',\n",
       "  'ever',\n",
       "  'see',\n",
       "  'rest',\n",
       "  'alex',\n",
       "  'jones',\n",
       "  'youtube',\n",
       "  'channel',\n",
       "  'illustration',\n",
       "  'much',\n",
       "  'healthcare',\n",
       "  'premiums',\n",
       "  'rise',\n",
       "  'infowarscom',\n",
       "  'free',\n",
       "  'speech',\n",
       "  'systems',\n",
       "  'llc',\n",
       "  'company',\n",
       "  'rights',\n",
       "  'reserved',\n",
       "  'digital',\n",
       "  'millennium',\n",
       "  'copyright',\n",
       "  'act',\n",
       "  'notice',\n",
       "  'flip',\n",
       "  'switch',\n",
       "  'supercharge',\n",
       "  'state',\n",
       "  'mind',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'neural',\n",
       "  'activation',\n",
       "  'infowars',\n",
       "  'life',\n",
       "  'httpwwwinfowarscomwpcontentuploadsbrainforceejpg',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'flip',\n",
       "  'switch',\n",
       "  'supercharge',\n",
       "  'state',\n",
       "  'mind',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'neural',\n",
       "  'activation',\n",
       "  'infowars',\n",
       "  'life',\n",
       "  'httpwwwinfowarscomwpcontentuploadsbrainforceejpg',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'flip',\n",
       "  'switch',\n",
       "  'supercharge',\n",
       "  'state',\n",
       "  'mind',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'neural',\n",
       "  'activation',\n",
       "  'infowars',\n",
       "  'life',\n",
       "  'httpwwwinfowarscomwpcontentuploadsbrainforceejpg',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'flip',\n",
       "  'switch',\n",
       "  'supercharge',\n",
       "  'state',\n",
       "  'mind',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'neural',\n",
       "  'activation',\n",
       "  'infowars',\n",
       "  'life',\n",
       "  'httpwwwinfowarscomwpcontentuploadsbrainforceejpg',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'flip',\n",
       "  'switch',\n",
       "  'supercharge',\n",
       "  'state',\n",
       "  'mind',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'neural',\n",
       "  'activation',\n",
       "  'infowars',\n",
       "  'life',\n",
       "  'httpwwwinfowarscomwpcontentuploadsbrainforceejpg',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'flip',\n",
       "  'switch',\n",
       "  'supercharge',\n",
       "  'state',\n",
       "  'mind',\n",
       "  'brain',\n",
       "  'force',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'neural',\n",
       "  'activation',\n",
       "  'infowars',\n",
       "  'life',\n",
       "  'httpwwwinfowarscomwpcontentuploadsbrainforceejpg',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce',\n",
       "  'httpwwwinfowarsstorecomhealthandwellnessinfowarslifebrainforcehtmlimstzrwuutm',\n",
       "  'campaigninfowarsplacementutm',\n",
       "  'sourceinfowarscomutm',\n",
       "  'mediumwidgetutm',\n",
       "  'contentbrainforce'],\n",
       " ['email',\n",
       "  'president',\n",
       "  'barack',\n",
       "  'obama',\n",
       "  'admonished',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'thursday',\n",
       "  'saying',\n",
       "  'republican',\n",
       "  'nominees',\n",
       "  'claims',\n",
       "  'might',\n",
       "  'accept',\n",
       "  'results',\n",
       "  'next',\n",
       "  'months',\n",
       "  'election',\n",
       "  'joking',\n",
       "  'matter',\n",
       "  'want',\n",
       "  'everybody',\n",
       "  'pay',\n",
       "  'attention',\n",
       "  'dangerous',\n",
       "  'obama',\n",
       "  'said',\n",
       "  'hillary',\n",
       "  'america',\n",
       "  'event',\n",
       "  'miami',\n",
       "  'gardens',\n",
       "  'florida',\n",
       "  'try',\n",
       "  'sow',\n",
       "  'seeds',\n",
       "  'doubt',\n",
       "  'peoples',\n",
       "  'mind',\n",
       "  'legitimacy',\n",
       "  'elections',\n",
       "  'undermines',\n",
       "  'democracy',\n",
       "  'work',\n",
       "  'adversaries',\n",
       "  'obama',\n",
       "  'also',\n",
       "  'encouraged',\n",
       "  'crowd',\n",
       "  'florida',\n",
       "  'memorial',\n",
       "  'university',\n",
       "  'take',\n",
       "  'advantage',\n",
       "  'floridas',\n",
       "  'early',\n",
       "  'voting',\n",
       "  'telling',\n",
       "  'audience',\n",
       "  'reject',\n",
       "  'president',\n",
       "  'called',\n",
       "  'trumps',\n",
       "  'dark',\n",
       "  'pessimistic',\n",
       "  'fearmongering',\n",
       "  'democracy',\n",
       "  'depends',\n",
       "  'people',\n",
       "  'knowing',\n",
       "  'vote',\n",
       "  'matters',\n",
       "  'occupy',\n",
       "  'seats',\n",
       "  'power',\n",
       "  'chosen',\n",
       "  'people',\n",
       "  'obama',\n",
       "  'said',\n",
       "  'wednesday',\n",
       "  'nights',\n",
       "  'debate',\n",
       "  'trump',\n",
       "  'answered',\n",
       "  'look',\n",
       "  'time',\n",
       "  'asked',\n",
       "  'whether',\n",
       "  'would',\n",
       "  'concede',\n",
       "  'loses',\n",
       "  'november',\n",
       "  'keep',\n",
       "  'suspense',\n",
       "  'trump',\n",
       "  'also',\n",
       "  'doubled',\n",
       "  'thursday',\n",
       "  'ohio',\n",
       "  'saying',\n",
       "  'accept',\n",
       "  'results',\n",
       "  'next',\n",
       "  'months',\n",
       "  'election',\n",
       "  'long',\n",
       "  'wins',\n",
       "  'obama',\n",
       "  'also',\n",
       "  'used',\n",
       "  'opportunity',\n",
       "  'florida',\n",
       "  'weigh',\n",
       "  'close',\n",
       "  'senate',\n",
       "  'race',\n",
       "  'florida',\n",
       "  'republican',\n",
       "  'sen',\n",
       "  'marco',\n",
       "  'rubio',\n",
       "  'democratic',\n",
       "  'challenger',\n",
       "  'rep',\n",
       "  'patrick',\n",
       "  'murphy',\n",
       "  'even',\n",
       "  'marco',\n",
       "  'rubio',\n",
       "  'says',\n",
       "  'theres',\n",
       "  'rigging',\n",
       "  'vote',\n",
       "  'obama',\n",
       "  'said',\n",
       "  'id',\n",
       "  'like',\n",
       "  'give',\n",
       "  'credit',\n",
       "  'except',\n",
       "  'hes',\n",
       "  'refuting',\n",
       "  'dangerous',\n",
       "  'unprecedented',\n",
       "  'claims',\n",
       "  'candidate',\n",
       "  'says',\n",
       "  'hes',\n",
       "  'still',\n",
       "  'going',\n",
       "  'vote',\n",
       "  'earlier',\n",
       "  'week',\n",
       "  'obama',\n",
       "  'released',\n",
       "  'new',\n",
       "  'ad',\n",
       "  'democrat',\n",
       "  'sunshine',\n",
       "  'state',\n",
       "  'week',\n",
       "  'announced',\n",
       "  'democratic',\n",
       "  'senatorial',\n",
       "  'campaign',\n",
       "  'committee',\n",
       "  'puling',\n",
       "  'money',\n",
       "  'ads',\n",
       "  'murphy']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f030dd",
   "metadata": {},
   "source": [
    "Количество текстов в корпусе не изменилось и соответствует целевому признаку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "142c5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset1.shape[0]==len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6353aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.91 s\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "%time model = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44a5da",
   "metadata": {},
   "source": [
    "Проверим, что модель обучилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5084214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 0.9726372361183167), ('little', 0.9723168611526489), ('always', 0.9715560674667358), ('whole', 0.9670679569244385), ('understand', 0.9665523767471313)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['find'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb553b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f10d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.size = model.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean(\n",
    "            [self.model[w] for w in words if w in self.model] \n",
    "            or [np.zeros(self.size)], axis=0)\n",
    "            for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57c00990",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = 1500\n",
    "X_train = corpus[:boundary] \n",
    "X_test = corpus[boundary:]\n",
    "y_train = dataset1['hasImage'][:boundary]\n",
    "y_test = dataset1['hasImage'][boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1ab74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0.0 \t 0.08888888888888889\n",
      "1.0 \t 0.980722891566265\n"
     ]
    }
   ],
   "source": [
    "sentiment(EmbeddingVectorizer(model.wv), LogisticRegression(C=5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9c19b",
   "metadata": {},
   "source": [
    "Лучшую точность показал word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920457c",
   "metadata": {},
   "source": [
    "источник базы данных - https://www.kaggle.com/datasets/ruchi798/source-based-news-classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
